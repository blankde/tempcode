
    /**
     * \brief Send the update messages (vertex data, program)
     * for the local vertex id to all of its mirrors.
     *
     * @param [in] lvid the vertex to sync.  It must be the master of that vertex.
     */
    void send_updates_activs(lvid_type lvid, size_t thread_id);

    /**
     * \brief do update and activation to local mirros.
     *
     * This function returns when there is nothing left in the
     * buffered exchange and should be called after the buffered
     * exchange has been flushed
     */
    void recv_updates_activs();


    /**
     * \brief Send the update messages (vertex data, program and edge set)
     * for the local vertex id to all of its mirrors.
     *
     * @param [in] lvid the vertex to sync.  It must be the master of that vertex.
     */
    void send_updates(lvid_type lvid, size_t thread_id);

    /**
     * \brief do update to local mirros.
     *
     * This function returns when there is nothing left in the
     * buffered exchange and should be called after the buffered
     * exchange has been flushed
     */
    void recv_updates();

    /**
     * \brief Send the gather accum for the vertex id to its master.
     *
     * @param [in] lvid the vertex to send the gather value to
     * @param [in] accum the locally computed gather value.
     */
    void send_accum(lvid_type lvid, const gather_type& accum,
                        const size_t thread_id);


    /**
     * \brief Receive the gather accums from the buffered exchange.
     *
     * This function returns when there is nothing left in the
     * buffered exchange and should be called after the buffered
     * exchange has been flushed
     */
    void recv_accums();

    /**
     * \brief Send the scatter messages for the vertex id to its master.
     *
     * @param [in] lvid the vertex to send
     */
    void send_message(lvid_type lvid, const size_t thread_id);

    /**
     * \brief Receive the scatter messages from the buffered exchange.
     *
     * This function returns when there is nothing left in the
     * buffered exchange and should be called after the buffered
     * exchange has been flushed
     */
    void recv_messages();


  }; // end of class topoX_sync_engine

























  /**
   * Constructs an synchronous distributed engine.
   * The number of threads to create are read from
   * opts::get_ncpus().
   *
   * Valid engine options (graphlab_options::get_engine_args()):
   * \arg \c max_iterations Sets the maximum number of iterations the
   * engine will run for.
   * \arg \c use_cache If set to true, partial gathers are cached.
   * See \ref gather_caching to understand the behavior of the
   * gather caching model and how it may be used to accelerate program
   * performance.
   *
   * \param dc Distributed controller to associate with
   * \param graph The graph to schedule over. The graph must be fully
   *              constructed and finalized.
   * \param opts A graphlab_options object containing options and parameters
   *             for the engine.
   */
  template<typename VertexProgram>
  topoX_sync_engine<VertexProgram>::
  topoX_sync_engine(distributed_control& dc,
                     graph_type& graph,
                     const graphlab_options& opts) :
    rmi(dc, this), graph(graph),
    ncpus(opts.get_ncpus()),
    threads(2*1024*1024 /* 2MB stack per fiber*/),
    thread_barrier(opts.get_ncpus()),
    max_iterations(-1), snapshot_interval(-1), iteration_counter(0),
    print_interval(5), timeout(0), sched_allv(false),
    activ_exchange(dc),
    update_activ_exchange(dc),
    update_exchange(dc),
    accum_exchange(dc),
    message_exchange(dc),
    aggregator(dc, graph, new context_type(*this, graph)) {
    // Process any additional options
    std::vector<std::string> keys = opts.get_engine_args().get_option_keys();
    per_thread_compute_time.resize(opts.get_ncpus());
	per_thread_low_time.resize(opts.get_ncpus());
	per_thread_high_time.resize(opts.get_ncpus());

	per_thread_gather_time.resize(opts.get_ncpus());
	per_thread_apply_time.resize(opts.get_ncpus());

	per_thread_high_time2.resize(opts.get_ncpus());

    use_cache = false;
    foreach(std::string opt, keys) {
      if (opt == "max_iterations") {
        opts.get_engine_args().get_option("max_iterations", max_iterations);
        if (rmi.procid() == 0)
          logstream(LOG_EMPH) << "Engine Option: max_iterations = "
            << max_iterations << std::endl;
      } else if (opt == "timeout") {
        opts.get_engine_args().get_option("timeout", timeout);
        if (rmi.procid() == 0)
          logstream(LOG_EMPH) << "Engine Option: timeout = "
            << timeout << std::endl;
      } else if (opt == "use_cache") {
        opts.get_engine_args().get_option("use_cache", use_cache);
        if (rmi.procid() == 0)
          logstream(LOG_EMPH) << "Engine Option: use_cache = "
            << use_cache << std::endl;
      } else if (opt == "snapshot_interval") {
        opts.get_engine_args().get_option("snapshot_interval", snapshot_interval);
        if (rmi.procid() == 0)
          logstream(LOG_EMPH) << "Engine Option: snapshot_interval = "
            << snapshot_interval << std::endl;
      } else if (opt == "snapshot_path") {
        opts.get_engine_args().get_option("snapshot_path", snapshot_path);
        if (rmi.procid() == 0)
          logstream(LOG_EMPH) << "Engine Option: snapshot_path = "
            << snapshot_path << std::endl;
      } else if (opt == "sched_allv") {
        opts.get_engine_args().get_option("sched_allv", sched_allv);
        if (rmi.procid() == 0)
          logstream(LOG_EMPH) << "Engine Option: sched_allv = "
            << sched_allv << std::endl;
      } else {
        logstream(LOG_FATAL) << "Unexpected Engine Option: " << opt << std::endl;
      }
    }

    if (snapshot_interval >= 0 && snapshot_path.length() == 0) {
      logstream(LOG_FATAL)
        << "Snapshot interval specified, but no snapshot path" << std::endl;
    }
    INITIALIZE_EVENT_LOG(dc);
    ADD_CUMULATIVE_EVENT(EVENT_APPLIES, "Applies", "Calls");
    ADD_CUMULATIVE_EVENT(EVENT_GATHERS , "Gathers", "Calls");
    ADD_CUMULATIVE_EVENT(EVENT_SCATTERS , "Scatters", "Calls");
    ADD_INSTANTANEOUS_EVENT(EVENT_ACTIVE_CPUS, "Active Threads", "Threads");
    graph.finalize();
    init();
  } // end of topoX_sync_engine


  template<typename VertexProgram>
  void topoX_sync_engine<VertexProgram>:: init() {
    memory_info::log_usage("Before Engine Initialization");

    resize();

    // Clear up
    force_abort = false;
    iteration_counter = 0;
    completed_gathers = 0;
    completed_applys = 0;
    completed_scatters = 0;
    has_message.clear();
    has_gather_accum.clear();
    has_cache.clear();
    active_superstep.clear();
    active_minorstep.clear();

    memory_info::log_usage("After Engine Initialization");
  }


  template<typename VertexProgram>
  void topoX_sync_engine<VertexProgram>:: resize() {
    size_t l_nverts = graph.num_local_vertices();

    // Allocate vertex locks and vertex programs
    vlocks.resize(l_nverts);
    vertex_programs.resize(l_nverts);

    // Allocate messages and message bitset
    messages.resize(l_nverts, message_type());
    has_message.resize(l_nverts);

    // Allocate gather accumulators and accumulator bitset
    gather_accum.resize(l_nverts, gather_type());
    has_gather_accum.resize(l_nverts);

    // If caching is used then allocate cache data-structures
    if (use_cache) {
      gather_cache.resize(l_nverts, gather_type());
      has_cache.resize(l_nverts);
    }
    // Allocate bitset to track active vertices on each bitset.
    active_superstep.resize(l_nverts);
    active_minorstep.resize(l_nverts);
  }


  template<typename VertexProgram>
  typename topoX_sync_engine<VertexProgram>::aggregator_type*
  topoX_sync_engine<VertexProgram>::get_aggregator() {
    return &aggregator;
  } // end of get_aggregator


  template<typename VertexProgram>
  void topoX_sync_engine<VertexProgram>::internal_stop() {
    for (size_t i = 0; i < rmi.numprocs(); ++i)
      rmi.remote_call(i, &engine_type::rpc_stop);
  } // end of internal_stop


  template<typename VertexProgram>
  void topoX_sync_engine<VertexProgram>::rpc_stop() {
    force_abort = true;
  } // end of rpc_stop


  template<typename VertexProgram>
  void topoX_sync_engine<VertexProgram>::
  signal(vertex_id_type gvid, const message_type& message) {
    if (vlocks.size() != graph.num_local_vertices())
      resize();
    rmi.barrier();
    internal_signal_rpc(gvid, message);
    rmi.barrier();
  } // end of signal



  template<typename VertexProgram>
  void topoX_sync_engine<VertexProgram>::
  signal_all(const message_type& message, const std::string& order) {
    if (vlocks.size() != graph.num_local_vertices())
      resize();
    for(lvid_type lvid = 0; lvid < graph.num_local_vertices(); ++lvid) {
      if(graph.l_is_master(lvid)) {
        internal_signal(vertex_type(graph.l_vertex(lvid)), message);
      }
    }
  } // end of signal all


  template<typename VertexProgram>
  void topoX_sync_engine<VertexProgram>::
  signal_vset(const vertex_set& vset,
             const message_type& message, const std::string& order) {
    if (vlocks.size() != graph.num_local_vertices())
      resize();
    for(lvid_type lvid = 0; lvid < graph.num_local_vertices(); ++lvid) {
      if(graph.l_is_master(lvid) && vset.l_contains(lvid)) {
        internal_signal(vertex_type(graph.l_vertex(lvid)), message);
      }
    }
  } // end of signal all


  template<typename VertexProgram>
  void topoX_sync_engine<VertexProgram>::
  internal_signal(const vertex_type& vertex,
                  const message_type& message) {
    const lvid_type lvid = vertex.local_id();
    vlocks[lvid].lock();
    if( has_message.get(lvid) ) {
      messages[lvid] += message;
    } else {
      messages[lvid] = message;
      has_message.set_bit(lvid);
    }
    vlocks[lvid].unlock();
  } // end of internal_signal

  template<typename VertexProgram>
  void topoX_sync_engine<VertexProgram>::
  internal_signal(const vertex_type& vertex) {
    const lvid_type lvid = vertex.local_id();
    // set an empty message
    messages[lvid] = message_type();
    // atomic set is enough, without acquiring and releasing lock
    has_message.set_bit(lvid);
  } // end of internal_signal

  template<typename VertexProgram>
  void topoX_sync_engine<VertexProgram>::
  internal_signal_gvid(vertex_id_type gvid, const message_type& message) {
    procid_t proc = graph.master(gvid);
    if(proc == rmi.procid()) internal_signal_rpc(gvid, message);
    else rmi.remote_call(proc,
                         &topoX_sync_engine<VertexProgram>::internal_signal_rpc,
                         gvid, message);
  } // end of internal_signal_gvid

  template<typename VertexProgram>
  void topoX_sync_engine<VertexProgram>::
  internal_signal_rpc(vertex_id_type gvid,
                      const message_type& message) {
    if (graph.is_master(gvid)) {
      internal_signal(graph.vertex(gvid), message);
    }
  } // end of internal_signal_rpc





  template<typename VertexProgram>
  void topoX_sync_engine<VertexProgram>::
  internal_post_delta(const vertex_type& vertex, const gather_type& delta) {
    const bool caching_enabled = !gather_cache.empty();
    if(caching_enabled) {
      const lvid_type lvid = vertex.local_id();
      vlocks[lvid].lock();
      if( has_cache.get(lvid) ) {
        gather_cache[lvid] += delta;
      } else {
        // You cannot add a delta to an empty cache.  A complete
        // gather must have been run.
        // gather_cache[lvid] = delta;
        // has_cache.set_bit(lvid);
      }
      vlocks[lvid].unlock();
    }
  } // end of post_delta


  template<typename VertexProgram>
  void topoX_sync_engine<VertexProgram>::
  internal_clear_gather_cache(const vertex_type& vertex) {
    const bool caching_enabled = !gather_cache.empty();
    const lvid_type lvid = vertex.local_id();
    if(caching_enabled && has_cache.get(lvid)) {
      vlocks[lvid].lock();
      gather_cache[lvid] = gather_type();
      has_cache.clear_bit(lvid);
      vlocks[lvid].unlock();
    }
  } // end of clear_gather_cache




  template<typename VertexProgram>
  size_t topoX_sync_engine<VertexProgram>::
  num_updates() const { return completed_applys.value; }

  template<typename VertexProgram>
  float topoX_sync_engine<VertexProgram>::
  elapsed_seconds() const { return timer::approx_time_seconds() - start_time; }

  template<typename VertexProgram>
  int topoX_sync_engine<VertexProgram>::
  iteration() const { return iteration_counter; }



  template<typename VertexProgram>
  size_t topoX_sync_engine<VertexProgram>::total_memory_usage() const {
    size_t allocated_memory = memory_info::allocated_bytes();
    rmi.all_reduce(allocated_memory);
    return allocated_memory;
  } // compute the total memory usage of the GraphLab system


  template<typename VertexProgram>
  execution_status::status_enum topoX_sync_engine<VertexProgram>::
  start() {
    if (vlocks.size() != graph.num_local_vertices())
      resize();
    completed_gathers = 0;
    completed_applys = 0;
    completed_scatters = 0;
    rmi.barrier();

    // Initialization code ==================================================
    // Reset event log counters?
    // Start the timer
    start_time = timer::approx_time_seconds();
#ifdef TUNING
    exec_time = exch_time = recv_time =
      gather_time = apply_time = scatter_time = 0.0;
    graphlab::timer ti, bk_ti;
#endif
    iteration_counter = 0;
    force_abort = false;
    execution_status::status_enum termination_reason = execution_status::UNSET;
    aggregator.start();
    rmi.barrier();

    if (snapshot_interval == 0) {
      graph.save_binary(snapshot_path);
    }

    float last_print = -print_interval; // print the first iteration
    if (rmi.procid() == 0) {
      logstream(LOG_EMPH) << "Iteration counter will only output every "
                          << print_interval << " seconds."
                          << std::endl;
    }

    // Program Main loop ====================================================
#ifdef TUNING
    ti.start();
#endif
    while(iteration_counter < max_iterations && !force_abort ) {

      // Check first to see if we are out of time
      if(timeout != 0 && timeout < elapsed_seconds()) {
        termination_reason = execution_status::TIMEOUT;
        break;
      }

      bool print_this_round = (elapsed_seconds() - last_print) >= print_interval;
      if(rmi.procid() == 0 && print_this_round) {
        logstream(LOG_DEBUG)
          << rmi.procid() << ": Starting iteration: " << iteration_counter
          << std::endl;
        last_print = elapsed_seconds();
      }
      // Reset Active vertices ----------------------------------------------
      // Clear the active super-step and minor-step bits which will
      // be set upon receiving messages
      active_superstep.clear(); active_minorstep.clear();
      has_gather_accum.clear();
      num_active_vertices = 0;
      rmi.barrier();


      // Exchange Messages --------------------------------------------------
      // High: send messages from mirrors to master
      // Low: none (if only IN_EDGES)
      //
      // if (rmi.procid() == 0) std::cout << "Exchange messages..." << std::endl;
#ifdef TUNING
      bk_ti.start();
#endif
      run_synchronous( &topoX_sync_engine::exchange_messages );
#ifdef TUNING
      exch_time += bk_ti.current_time();
#endif
      /**
       * Post conditions:
       *   1) master (high and low) vertices have messages
       */

      // Receive Messages ---------------------------------------------------
      // 1. calculate the number of active vertices
      // 2. call init and gather_edges
      // 3. set active_superstep, active_minorstep and edge_dirs
      // 4. clear has_message
      //
      // High: send vprog and edge_dirs from master to mirrors
      // Low: none (if only IN_EDGES)
      //
      // if (rmi.procid() == 0) std::cout << "Receive messages..." << std::endl;
#ifdef TUNING
      bk_ti.start();
#endif
      run_synchronous( &topoX_sync_engine::receive_messages );
      if (sched_allv) active_minorstep.fill();
      has_message.clear();
#ifdef TUNING
      recv_time += bk_ti.current_time();
#endif
      /**
       * Post conditions:
       *   1) there are no messages remaining
       *   2) All masters that received messages have their
       *      active_superstep bit set
       *   3) All masters and mirrors that are to participate in the
       *      next gather phases have their active_minorstep bit
       *      set.
       *   4) num_active_vertices is the number of vertices that
       *      received messages.
       */

      // Check termination condition  ---------------------------------------
      size_t total_active_vertices = num_active_vertices;
      rmi.all_reduce(total_active_vertices);
      if (rmi.procid() == 0 && print_this_round)
        logstream(LOG_EMPH)
          << "\tActive vertices: " << total_active_vertices << std::endl;
      if(total_active_vertices == 0 ) {
        termination_reason = execution_status::TASK_DEPLETION;
        break;
      }


      // Execute gather operations-------------------------------------------
      // 1. call pre_local_gather, gather and post_local_gather
      // 2. (master) set gather_accum and has_gather_accum
      // 3. clear active_minorstep
      //
      // High: send gather_accum from mirrors to master
      // Low: none (if only IN_EDGES)
      //
      // if (rmi.procid() == 0) std::cout << "Gathering..." << std::endl;
#ifdef TUNING
      bk_ti.start();
#endif
      run_synchronous( &topoX_sync_engine::execute_gathers );
      // Clear the minor step bit since only super-step vertices
      // (only master vertices are required to participate in the
      // apply step)
      active_minorstep.clear();
#ifdef TUNING

      gather_time += bk_ti.current_time();
#endif
      /**
       * Post conditions:
       *   1) gather_accum for all master vertices contains the
       *      result of all the gathers (even if they are drawn from
       *      cache)
       *   2) No minor-step bits are set
       */

      // Execute Apply Operations -------------------------------------------
      // 1. call apply and scatter_edges
      // 2. set edge_dirs and active_minorstep
      // 3. send vdata, vprog and edge_dirs from master to replicas
      //
      // if (rmi.procid() == 0) std::cout << "Applying..." << std::endl;
#ifdef TUNING
      bk_ti.start();
#endif
      run_synchronous( &topoX_sync_engine::execute_applys );
#ifdef TUNING

      apply_time += bk_ti.current_time();
#endif
      /**
       * Post conditions:
       *   1) any changes to the vertex data have been synchronized
       *      with all mirrors.
       *   2) all gather accumulators have been cleared
       *   3) If a vertex program is participating in the scatter
       *      phase its minor-step bit has been set to active (both
       *      masters and mirrors) and the vertex program has been
       *      synchronized with the mirrors.
       */


      // Execute Scatter Operations -----------------------------------------
      // 1. call scatter (signal: set messages and has_message)
      //
      // if (rmi.procid() == 0) std::cout << "Scattering..." << std::endl;
#ifdef TUNING
      bk_ti.start();
#endif
      run_synchronous( &topoX_sync_engine::execute_scatters );
#ifdef TUNING

      scatter_time += bk_ti.current_time();
#endif
      /**
       * Post conditions:
       *   1) NONE
       */
      if(rmi.procid() == 0 && print_this_round)
        logstream(LOG_EMPH) << "\t Running Aggregators" << std::endl;
      // probe the aggregator
      aggregator.tick_synchronous();

      ++iteration_counter;

      if (snapshot_interval > 0 && iteration_counter % snapshot_interval == 0) {
        graph.save_binary(snapshot_path);
      }
    }
#ifdef TUNING
    exec_time = ti.current_time();
#endif

    if (rmi.procid() == 0) {
      logstream(LOG_EMPH) << iteration_counter
                          << " iterations completed." << std::endl;
    }
    // Final barrier to ensure that all engines terminate at the same time
    double total_compute_time = 0;
	double total_low_time = 0;
	double total_high_comm_time = 0;
	double total_gather_time = 0;
	double total_apply_comm_time = 0;
    for (size_t i = 0;i < per_thread_compute_time.size(); ++i) {
      total_compute_time += per_thread_compute_time[i];
	  total_low_time += per_thread_low_time[i];
	  total_high_comm_time += per_thread_high_time[i];
	  total_gather_time += per_thread_gather_time[i];
	  total_apply_comm_time += per_thread_high_time2[i];
    }
    std::vector<double> all_compute_time_vec(rmi.numprocs());
	std::vector<double> all_low_time_vec(rmi.numprocs());
	std::vector<double> all_high_comm_time_vec(rmi.numprocs());
	std::vector<double> all_gather_time_vec(rmi.numprocs());
	std::vector<double> all_apply_comm_time_vec(rmi.numprocs());
    all_compute_time_vec[rmi.procid()] = total_compute_time;
	all_low_time_vec[rmi.procid()] = total_low_time;
	all_high_comm_time_vec[rmi.procid()] = total_high_comm_time;
	all_gather_time_vec[rmi.procid()] = total_gather_time;
	all_apply_comm_time_vec[rmi.procid()] = total_apply_comm_time;
    rmi.all_gather(all_compute_time_vec);
	rmi.all_gather(all_low_time_vec);
	rmi.all_gather(all_high_comm_time_vec);
	rmi.all_gather(all_gather_time_vec);
	rmi.all_gather(all_apply_comm_time_vec);

    /*logstream(LOG_INFO) << "Local Calls(G|A|S): "
                        << completed_gathers.value << "|"
                        << completed_applys.value << "|"
                        << completed_scatters.value
                        << std::endl;*/

    size_t global_completed = completed_applys;
    rmi.all_reduce(global_completed);
    completed_applys = global_completed;
    rmi.cout() << "Updates: " << completed_applys.value << "\n";

#ifdef TUNING
    global_completed = completed_gathers;
    rmi.all_reduce(global_completed);
    completed_gathers = global_completed;

    global_completed = completed_scatters;
    rmi.all_reduce(global_completed);
    completed_scatters = global_completed;
#endif

    if (rmi.procid() == 0) {
      std::cout << "Compute Balance: ";
      for (size_t i = 0;i < all_compute_time_vec.size(); ++i) {
		  std::cout << all_compute_time_vec[i] << " ";
      }
	  std::cout << std::endl;
	  std::cout << "Low time per proc in gather: ";
	  for (size_t i = 0; i < all_low_time_vec.size(); ++i) {
		  std::cout << all_low_time_vec[i] << " ";
	  }
	  std::cout << std::endl;
	  std::cout << "High communication time per proc in gather: ";
	  for (size_t i = 0; i < all_high_comm_time_vec.size(); ++i) {
		  std::cout << all_high_comm_time_vec[i] << " ";
	  }
	  std::cout << std::endl;
	  std::cout << "gather time per proc in gather: ";
	  for (size_t i = 0; i < all_gather_time_vec.size(); ++i) {
		  std::cout << all_gather_time_vec[i] << " ";
	  }
	  std::cout << std::endl;
	  std::cout << "apply communication time per proc in gather: ";
	  for (size_t i = 0; i < all_apply_comm_time_vec.size(); ++i) {
		  std::cout << all_apply_comm_time_vec[i] << " ";
	  }
	  std::cout << std::endl;
#ifdef TUNING
      logstream(LOG_INFO) << "Total Calls(G|A|S): "
							<< completed_gathers.value << "|"
                          << completed_applys.value << "|"
                          << completed_scatters.value
                          << std::endl;
      logstream(LOG_INFO) << std::endl;
      logstream(LOG_EMPH) << "      Execution Time: " << exec_time << std::endl;
	  rmi.cout() << "      Execution Time: " << exec_time << std::endl;
	  rmi.cout() << "Breakdown(X|R|G|A|S): "
                          << exch_time << "|"
                          << recv_time << "|"
                          << gather_time << "|"
                          << apply_time << "|"
                          << scatter_time
                          << std::endl;
#endif
    }

    rmi.full_barrier();
    // Stop the aggregator
    aggregator.stop();
    // return the final reason for termination
    return termination_reason;
  } // end of start

  template<typename VertexProgram>
  inline bool topoX_sync_engine<VertexProgram>::
  high_lvid(const lvid_type lvid) {
    return graph.l_degree_type(lvid) == graph_type::HIGH;
  }

  template<typename VertexProgram>
  inline bool topoX_sync_engine<VertexProgram>::
  low_lvid(const lvid_type lvid) {
    return graph.l_degree_type(lvid) == graph_type::LOW;
  }

  template<typename VertexProgram>
  void topoX_sync_engine<VertexProgram>::
  exchange_messages(const size_t thread_id) {
    context_type context(*this, graph);
    fixed_dense_bitset<8 * sizeof(size_t)> local_bitset; // a word-size = 64 bit
    const size_t TRY_RECV_MOD = 100;
    size_t vcount = 1; // avoid unnecessarily call recv_messages()

    while (1) {
      // increment by a word at a time
      lvid_type lvid_block_start =
                  shared_lvid_counter.inc_ret_last(8 * sizeof(size_t));
      if (lvid_block_start >= graph.num_local_vertices()) break;
      // get the bit field from has_message
      size_t lvid_bit_block = has_message.containing_word(lvid_block_start);
      if (lvid_bit_block == 0) continue;
      // initialize a word sized bitfield
      local_bitset.clear();
      local_bitset.initialize_from_mem(&lvid_bit_block, sizeof(size_t));
      foreach(size_t lvid_block_offset, local_bitset) {
        lvid_type lvid = lvid_block_start + lvid_block_offset;
        if (lvid >= graph.num_local_vertices()) break;

        // [TARGET]: High/Low-degree Mirrors
        if(!graph.l_is_master(lvid)) {
          send_message(lvid, thread_id);
          has_message.clear_bit(lvid);
          // clear the message to save memory
          messages[lvid] = message_type();
          ++vcount;
        }
        if(vcount % TRY_RECV_MOD == 0) recv_messages();
      }
    } // end of loop over vertices to send messages
    message_exchange.partial_flush();
    // Finish sending and receiving all messages
    thread_barrier.wait();
    if(thread_id == 0) message_exchange.flush();
    thread_barrier.wait();
    recv_messages();
  } // end of exchange_messages


  template<typename VertexProgram>
  void topoX_sync_engine<VertexProgram>::
  receive_messages(const size_t thread_id) {
    context_type context(*this, graph);
    fixed_dense_bitset<8 * sizeof(size_t)> local_bitset; // a word-size = 64 bit
    const size_t TRY_RECV_MOD = 100;
    size_t vcount = 0;
    size_t nactive_inc = 0;

    while (1) {
      // increment by a word at a time
      lvid_type lvid_block_start =
                  shared_lvid_counter.inc_ret_last(8 * sizeof(size_t));
      if (lvid_block_start >= graph.num_local_vertices()) break;
      // get the bit field from has_message
      size_t lvid_bit_block = has_message.containing_word(lvid_block_start);
      if (lvid_bit_block == 0) continue;
      // initialize a word sized bitfield
      local_bitset.clear();
      local_bitset.initialize_from_mem(&lvid_bit_block, sizeof(size_t));
      foreach(size_t lvid_block_offset, local_bitset) {
        lvid_type lvid = lvid_block_start + lvid_block_offset;
        if (lvid >= graph.num_local_vertices()) break;

        ASSERT_TRUE(graph.l_is_master(lvid));
        // The vertex becomes active for this superstep
        active_superstep.set_bit(lvid);
        ++nactive_inc;
        // Pass the message to the vertex program
        const vertex_type vertex(graph.l_vertex(lvid));
        vertex_programs[lvid].init(context, vertex, messages[lvid]);
        // clear the message to save memory
        messages[lvid] = message_type();
        if (sched_allv) continue;
        // Determine if the gather should be run
        const vertex_program_type& const_vprog = vertex_programs[lvid];
        edge_dir_type gather_dir = const_vprog.gather_edges(context, vertex);
        if(gather_dir != graphlab::NO_EDGES) {
          active_minorstep.set_bit(lvid);
          // send Gx1 msgs
          if (high_lvid(lvid)
              || (low_lvid(lvid) // only if gather via out-edge
                && ((gather_dir == graphlab::ALL_EDGES)
                    || (gather_dir == graphlab::OUT_EDGES)))) {
            send_activs(lvid, thread_id);
          }
        }
        if(++vcount % TRY_RECV_MOD == 0) recv_activs();
      }
    }
    num_active_vertices += nactive_inc;
    activ_exchange.partial_flush();
    // Flush the buffer and finish receiving any remaining vertex
    // programs.
    thread_barrier.wait();
    // Flush the buffer and finish receiving any remaining activations.
    if(thread_id == 0) activ_exchange.flush();
    thread_barrier.wait();
    recv_activs();
  } // end of receive_messages


  template<typename VertexProgram>
  void topoX_sync_engine<VertexProgram>::
  execute_gathers(const size_t thread_id) {
    context_type context(*this, graph);
    const bool caching_enabled = !gather_cache.empty();
    fixed_dense_bitset<8 * sizeof(size_t)> local_bitset; // a word-size = 64 bit
    const size_t TRY_RECV_MOD = 1000;
    size_t vcount = 0;
    size_t ngather_inc = 0;
    timer ti;
	double time_temp = 0;

    while (1) {
      // increment by a word at a time
      lvid_type lvid_block_start =
                  shared_lvid_counter.inc_ret_last(8 * sizeof(size_t));
      if (lvid_block_start >= graph.num_local_vertices()) break;
      // get the bit field from has_message
      size_t lvid_bit_block = active_minorstep.containing_word(lvid_block_start);
      if (lvid_bit_block == 0) continue;
      // initialize a word sized bitfield
      local_bitset.clear();
      local_bitset.initialize_from_mem(&lvid_bit_block, sizeof(size_t));
      foreach(size_t lvid_block_offset, local_bitset) {
		  time_temp = ti.current_time();
        lvid_type lvid = lvid_block_start + lvid_block_offset;
        if (lvid >= graph.num_local_vertices()) break;

        // [TARGET]: High/Low-degree Masters, and High/Low-degree Mirrors
        bool accum_is_set = false;
        gather_type accum = gather_type();
        // if caching is enabled and we have a cache entry then use
        // that as the accum
        if (caching_enabled && has_cache.get(lvid)) {
          accum = gather_cache[lvid];
          accum_is_set = true;
        } else {
          // recompute the local contribution to the gather
          const vertex_program_type& vprog = vertex_programs[lvid];
          local_vertex_type local_vertex = graph.l_vertex(lvid);
          const vertex_type vertex(local_vertex);
          const edge_dir_type gather_dir = vprog.gather_edges(context, vertex);

          size_t edges_touched = 0;
          vprog.pre_local_gather(accum);
          // Loop over in edges
          if (gather_dir == IN_EDGES || gather_dir == ALL_EDGES) {
            foreach(local_edge_type local_edge, local_vertex.in_edges()) {
              edge_type edge(local_edge);
              // elocks[local_edge.id()].lock();
              if(accum_is_set) { // \todo hint likely
                accum += vprog.gather(context, vertex, edge);
              } else {
                accum = vprog.gather(context, vertex, edge);
                accum_is_set = true;
              }
              // elocks[local_edge.id()].unlock();
              ++edges_touched;
            }
          } // end of if in_edges/all_edges
          // Loop over out edges
          if(gather_dir == OUT_EDGES || gather_dir == ALL_EDGES) {
            foreach(local_edge_type local_edge, local_vertex.out_edges()) {
              edge_type edge(local_edge);
              // elocks[local_edge.id()].lock();
              if(accum_is_set) { // \todo hint likely
                accum += vprog.gather(context, vertex, edge);
              } else {
                accum = vprog.gather(context, vertex, edge);
                accum_is_set = true;
              }
              // elocks[local_edge.id()].unlock();
              ++edges_touched;
            }
          } // end of if out_edges/all_edges
          INCREMENT_EVENT(EVENT_GATHERS, edges_touched);
          ++ngather_inc;
          vprog.post_local_gather(accum);

          // If caching is enabled then save the accumulator to the
          // cache for future iterations.  Note that it is possible
          // that the accumulator was never set in which case we are
          // effectively "zeroing out" the cache.
          if(caching_enabled && accum_is_set) {
            gather_cache[lvid] = accum; has_cache.set_bit(lvid);
          } // end of if caching enabled
        }

        // If the accum contains a value for the gather
		if (accum_is_set){
			if (high_lvid(lvid)){
				time_temp = ti.current_time();
				send_accum(lvid, accum, thread_id);
				per_thread_high_time[thread_id] += (ti.current_time() - time_temp);
			}
			else
				send_accum(lvid, accum, thread_id);
		}
        if(!graph.l_is_master(lvid)) {
          // if this is not the master clear the vertex program
          vertex_programs[lvid] = vertex_program_type();
        }

        // try to recv gathers if there are any in the buffer
        if(++vcount % TRY_RECV_MOD == 0) recv_accums();
		if (low_lvid(lvid))  per_thread_low_time[thread_id] += (ti.current_time()-time_temp);
      }
    } // end of loop over vertices to compute gather accumulators
    completed_gathers += ngather_inc;
    per_thread_compute_time[thread_id] += ti.current_time();
	per_thread_gather_time[thread_id] += ti.current_time();
    accum_exchange.partial_flush();
    // Finish sending and receiving all gather operations
    thread_barrier.wait();
    if(thread_id == 0) accum_exchange.flush();
    thread_barrier.wait();
    recv_accums();
  } // end of execute_gathers


  template<typename VertexProgram>
  void topoX_sync_engine<VertexProgram>::
  execute_applys(const size_t thread_id) {
    context_type context(*this, graph);
    fixed_dense_bitset<8 * sizeof(size_t)> local_bitset;  // allocate a word size = 64bits
    const size_t TRY_RECV_MOD = 1000;
    size_t vcount = 0;
    size_t napply_inc = 0;
    timer ti;
	double time_temp = 0;
    while (1) {
      // increment by a word at a time
      lvid_type lvid_block_start =
                  shared_lvid_counter.inc_ret_last(8 * sizeof(size_t));
      if (lvid_block_start >= graph.num_local_vertices()) break;
      // get the bit field from has_message
      size_t lvid_bit_block = active_superstep.containing_word(lvid_block_start);
      if (lvid_bit_block == 0) continue;
      // initialize a word sized bitfield
      local_bitset.clear();
      local_bitset.initialize_from_mem(&lvid_bit_block, sizeof(size_t));
      foreach(size_t lvid_block_offset, local_bitset) {
        lvid_type lvid = lvid_block_start + lvid_block_offset;
        if (lvid >= graph.num_local_vertices()) break;

        // [TARGET]: High/Low-degree Masters
        // Only master vertices can be active in a super-step
        ASSERT_TRUE(graph.l_is_master(lvid));
        vertex_type vertex(graph.l_vertex(lvid));
        // Get the local accumulator.  Note that it is possible that
        // the gather_accum was not set during the gather.
        const gather_type& accum = gather_accum[lvid];
        INCREMENT_EVENT(EVENT_APPLIES, 1);
        vertex_programs[lvid].apply(context, vertex, accum);
        // record an apply as a completed task
        ++napply_inc;
        // clear the accumulator to save some memory
        gather_accum[lvid] = gather_type();
        // determine if a scatter operation is needed
        const vertex_program_type& const_vprog = vertex_programs[lvid];
        const vertex_type const_vertex = vertex;

        if (const_vprog.scatter_edges(context, const_vertex)
            != graphlab::NO_EDGES) {
          // send Ax1 and Sx1
			time_temp = ti.current_time();
          send_updates_activs(lvid, thread_id);
		  per_thread_high_time2[thread_id] += (ti.current_time() - time_temp);
          active_minorstep.set_bit(lvid);
        } else {
          // send Ax1
			time_temp = ti.current_time();
          send_updates(lvid, thread_id);
		  per_thread_high_time2[thread_id] += (ti.current_time() - time_temp);
          vertex_programs[lvid] = vertex_program_type();
        }

        if(++vcount % TRY_RECV_MOD == 0) {
          recv_updates_activs(); recv_updates();
        }
      }
    } // end of loop over vertices to run apply
    completed_applys += napply_inc;
    per_thread_compute_time[thread_id] += ti.current_time();
	per_thread_apply_time[thread_id] += ti.current_time();
    update_activ_exchange.partial_flush(); update_exchange.partial_flush();
    thread_barrier.wait();
    // Flush the buffer and finish receiving any remaining updates.
    if(thread_id == 0) {
      update_activ_exchange.flush(); update_exchange.flush();
    }
    thread_barrier.wait();
    recv_updates_activs(); recv_updates();

  } // end of execute_applys


  template<typename VertexProgram>
  void topoX_sync_engine<VertexProgram>::
  execute_scatters(const size_t thread_id) {
    context_type context(*this, graph);
    fixed_dense_bitset<8 * sizeof(size_t)> local_bitset; // allocate a word size = 64 bits
    size_t nscatter_inc = 0;
    timer ti;

    while (1) {
      // increment by a word at a time
      lvid_type lvid_block_start =
                  shared_lvid_counter.inc_ret_last(8 * sizeof(size_t));
      if (lvid_block_start >= graph.num_local_vertices()) break;
      // get the bit field from has_message
      size_t lvid_bit_block = active_minorstep.containing_word(lvid_block_start);
      if (lvid_bit_block == 0) continue;
      // initialize a word sized bitfield
      local_bitset.clear();
      local_bitset.initialize_from_mem(&lvid_bit_block, sizeof(size_t));
      foreach(size_t lvid_block_offset, local_bitset) {
        lvid_type lvid = lvid_block_start + lvid_block_offset;
        if (lvid >= graph.num_local_vertices()) break;

        // [TARGET]: High/Low-degree Masters, and High/Low-degree Mirrors
        const vertex_program_type& vprog = vertex_programs[lvid];
        local_vertex_type local_vertex = graph.l_vertex(lvid);
        const vertex_type vertex(local_vertex);
        const edge_dir_type scatter_dir = vprog.scatter_edges(context, vertex);

        size_t edges_touched = 0;
        // Loop over in edges
        if(scatter_dir == IN_EDGES || scatter_dir == ALL_EDGES) {
          foreach(local_edge_type local_edge, local_vertex.in_edges()) {
            edge_type edge(local_edge);
            // elocks[local_edge.id()].lock();
            vprog.scatter(context, vertex, edge);
            // elocks[local_edge.id()].unlock();
            ++edges_touched;
          }
        } // end of if in_edges/all_edges
        // Loop over out edges
        if(scatter_dir == OUT_EDGES || scatter_dir == ALL_EDGES) {
          foreach(local_edge_type local_edge, local_vertex.out_edges()) {
            edge_type edge(local_edge);
            // elocks[local_edge.id()].lock();
            vprog.scatter(context, vertex, edge);
            // elocks[local_edge.id()].unlock();
            ++edges_touched;
          }
        } // end of if out_edges/all_edges
        INCREMENT_EVENT(EVENT_SCATTERS, edges_touched);
        // Clear the vertex program
        vertex_programs[lvid] = vertex_program_type();
        ++nscatter_inc;
      } // end of if active on this minor step
    } // end of loop over vertices to complete scatter operation
    completed_scatters += nscatter_inc;
    per_thread_compute_time[thread_id] += ti.current_time();
  } // end of execute_scatters



  // Data Synchronization ===================================================
  template<typename VertexProgram>
  inline void topoX_sync_engine<VertexProgram>::
  send_activs(lvid_type lvid, const size_t thread_id) {
    ASSERT_TRUE(graph.l_is_master(lvid));
    const vertex_id_type vid = graph.global_vid(lvid);
    local_vertex_type vertex = graph.l_vertex(lvid);
    foreach(const procid_t& mirror, vertex.mirrors()) {
      activ_exchange.send(mirror,
                          std::make_pair(vid, vertex_programs[lvid]));
    }
  } // end of send_activ

  template<typename VertexProgram>
  inline void topoX_sync_engine<VertexProgram>::
  recv_activs() {
    typename activ_exchange_type::recv_buffer_type recv_buffer;
    while(activ_exchange.recv(recv_buffer)) {
      for (size_t i = 0;i < recv_buffer.size(); ++i) {
        typename activ_exchange_type::buffer_type& buffer = recv_buffer[i].buffer;
        foreach(const vid_vprog_pair_type& pair, buffer) {
          const lvid_type lvid = graph.local_vid(pair.first);
          ASSERT_FALSE(graph.l_is_master(lvid));
          vertex_programs[lvid] = pair.second;
          active_minorstep.set_bit(lvid);
        }
      }
    }
  } // end of recv activs programs

  template<typename VertexProgram>
  inline void topoX_sync_engine<VertexProgram>::
  send_updates_activs(lvid_type lvid, const size_t thread_id) {
    ASSERT_TRUE(graph.l_is_master(lvid));
    const vertex_id_type vid = graph.global_vid(lvid);
    local_vertex_type vertex = graph.l_vertex(lvid);
    foreach(const procid_t& mirror, vertex.mirrors()) {
      update_activ_exchange.send(mirror,
                           make_triple(vid,
                                       vertex.data(),
                                       vertex_programs[lvid]));
    }
  } // end of send_update

  template<typename VertexProgram>
  inline void topoX_sync_engine<VertexProgram>::
  recv_updates_activs() {
    typename update_activ_exchange_type::recv_buffer_type recv_buffer;
    while(update_activ_exchange.recv(recv_buffer)) {
      for (size_t i = 0;i < recv_buffer.size(); ++i) {
        update_activ_buffer_type& buffer = recv_buffer[i].buffer;
        foreach(const vid_vdata_vprog_triple_type& t, buffer) {
          const lvid_type lvid = graph.local_vid(t.first);
          ASSERT_FALSE(graph.l_is_master(lvid));
          graph.l_vertex(lvid).data() = t.second;
          vertex_programs[lvid] = t.third;
          active_minorstep.set_bit(lvid);
        }
      }
    }
  } // end of recv_updates

  template<typename VertexProgram>
  inline void topoX_sync_engine<VertexProgram>::
  send_updates(lvid_type lvid, const size_t thread_id) {
    ASSERT_TRUE(graph.l_is_master(lvid));
    const vertex_id_type vid = graph.global_vid(lvid);
    local_vertex_type vertex = graph.l_vertex(lvid);
    foreach(const procid_t& mirror, vertex.mirrors()) {
      update_exchange.send(mirror, std::make_pair(vid, vertex.data()));
    }
  } // end of send_update

  template<typename VertexProgram>
  inline void topoX_sync_engine<VertexProgram>::
  recv_updates() {
    typename update_exchange_type::recv_buffer_type recv_buffer;
    while(update_exchange.recv(recv_buffer)) {
      for (size_t i = 0;i < recv_buffer.size(); ++i) {
        update_buffer_type& buffer = recv_buffer[i].buffer;
        foreach(const vid_vdata_pair_type& pair, buffer) {
          const lvid_type lvid = graph.local_vid(pair.first);
          ASSERT_FALSE(graph.l_is_master(lvid));
          graph.l_vertex(lvid).data() = pair.second;
        }
      }
    }
  } // end of recv_updates

  template<typename VertexProgram>
  inline void topoX_sync_engine<VertexProgram>::
  send_accum(lvid_type lvid, const gather_type& accum, const size_t thread_id) {
    if(graph.l_is_master(lvid)) {
      vlocks[lvid].lock();
      if(has_gather_accum.get(lvid)) {
        gather_accum[lvid] += accum;
      } else {
        gather_accum[lvid] = accum;
        has_gather_accum.set_bit(lvid);
      }
      vlocks[lvid].unlock();
    } else {
      const procid_t master = graph.l_master(lvid);
      const vertex_id_type vid = graph.global_vid(lvid);
      accum_exchange.send(master, std::make_pair(vid, accum));
    }
  } // end of send_accum

  template<typename VertexProgram>
  inline void topoX_sync_engine<VertexProgram>::
  recv_accums() {
    typename accum_exchange_type::recv_buffer_type recv_buffer;
    while(accum_exchange.recv(recv_buffer)) {
      for (size_t i = 0; i < recv_buffer.size(); ++i) {
        typename accum_exchange_type::buffer_type& buffer = recv_buffer[i].buffer;
        foreach(const vid_gather_pair_type& pair, buffer) {
          const lvid_type lvid = graph.local_vid(pair.first);
          const gather_type& acc = pair.second;
          ASSERT_TRUE(graph.l_is_master(lvid));
          vlocks[lvid].lock();
          if(has_gather_accum.get(lvid)) {
            gather_accum[lvid] += acc;
          } else {
            gather_accum[lvid] = acc;
            has_gather_accum.set_bit(lvid);
          }
          vlocks[lvid].unlock();
        }
      }
    }
  } // end of recv_accums


  template<typename VertexProgram>
  inline void topoX_sync_engine<VertexProgram>::
  send_message(lvid_type lvid, const size_t thread_id) {
    ASSERT_FALSE(graph.l_is_master(lvid));
    const procid_t master = graph.l_master(lvid);
    const vertex_id_type vid = graph.global_vid(lvid);
    message_exchange.send(master, std::make_pair(vid, messages[lvid]));
  } // end of send_message

  template<typename VertexProgram>
  inline void topoX_sync_engine<VertexProgram>::
  recv_messages() {
    typename message_exchange_type::recv_buffer_type recv_buffer;
    while(message_exchange.recv(recv_buffer)) {
      for (size_t i = 0;i < recv_buffer.size(); ++i) {
        typename message_exchange_type::buffer_type& buffer = recv_buffer[i].buffer;
        foreach(const vid_message_pair_type& pair, buffer) {
          const lvid_type lvid = graph.local_vid(pair.first);
          const message_type& msg = pair.second;
          ASSERT_TRUE(graph.l_is_master(lvid));
          vlocks[lvid].lock();
          if(has_message.get(lvid)) {
            messages[lvid] += msg;
          } else {
            messages[lvid] = msg;
            has_message.set_bit(lvid);
          }
          vlocks[lvid].unlock();
        }
      }
    }
  } // end of recv_messages

}; // namespace


#include <graphlab/macros_undef.hpp>

#endif

